\documentclass{llncs}

\usepackage{amsmath,stmaryrd,natbib}
\usepackage[usenames,dvipsnames]{color}

\newcommand{\Scribtexttt}[1]{{\texttt{#1}}}
\newcommand{\SColorize}[2]{\color{#1}{#2}}
\newcommand{\inColor}[2]{{\Scribtexttt{\SColorize{#1}{#2}}}}
\definecolor{PaleBlue}{rgb}{0.90,0.90,1.0}
\newcommand{\rackett}[1]{\inColor{black}{#1}}
\input{local-macros}

\title{Concrete Semantics for Pushdown Analysis:\\The Essence of Summarization}
\author{J. Ian Johnson and David Van Horn}
\institute{Northeastern University \\
           \email{\{ianj,dvanhorn\}@ccs.neu.edu}}

\usepackage{hyperref}
\begin{document}
\maketitle

% Outline:
% Introduction.
% High level
% PDCFA
% - Concrete
% - Abstract
% CFA2
% - Concrete
% - Abstract
% WCM machine
% - Concrete
% - Abstract
% Related Work
% Future Work
% Conclusion

\section{Introduction}

Programs in higher-order languages heavily use function calls and
method dispatch as part of their control flow. Until recently, flow
analyses could not handle return flow precisely
\citep{ianjohnson:vardoulakis-lmcs11, ianjohnson:earl2010pdcfa}, which
leads to several spurious paths (and thus false positives) due to
their pervasiveness. These works, called CFA2 and PDCFA respectively,
use pushdown automata as their approximation's target model of
computation. They are hence called ``pushdown analyses.''\footnote{We
  will refer to the classic finite model analyses as ``regular
  analyses'' after regular languages.} The precision and performance
gains of these analyses are so beneficial that we believe new analyses
going forward should be using pushdown techniques. CFA2 and PDCFA have
difficult details to easily apply to an off-the-shelf semantics ---
especially if they feature non-local control transfer that breaks the
pushdown model. 

...


\section{What to expect}

CFA2 uses a technique called ``summarization'' from
\citet[Chapter 7]{local:muchnick:jones:flow-analysis:1981}, which is synonymous with the
$\epsilon$-closure graph that PDCFA constructs. Summarization
algorithms need not be restricted to languages with well-bracketed
calls and returns. We can adopt the technique for higher precision in
the common case but still handle difficult cases such as first-class
control. This was shown for the
\rackett{call-with-current-continuation} (a.k.a. \rackett{call/cc})
operator in ~\citet{ianjohnson:Vardoulakis2011Pushdown}. This
impressive work illuminated the fact that we can harness the enhanced
technology of pushdown analyses in non-pushdown models of
computation. Doing this sacrifices call/return matching in the general
case, but in practice the precision is much better than the
alternative regular model that, say, AAM would provide.

This paper lays out a common framework to talk about pushdown analysis
for higher-order languages. In particular, we extract the ``essence''
of the existing techniques into a quality of the machine semantics
that specify a language's meaning, much in the same way as
~\citet{dvanhorn:VanHorn2012Systematic} (a method we will refer to as
AAM: abstracting abstract machines). Once the machine semantics is in
this form, simple pointwise abstraction leads to the summarization
algorithms that we see in the literature. In effect, we give a
\emph{concrete} semantics to pushdown analysis.

A downside of the work providing \rackett{call/cc} is that it was an
algorithmic change to the already complicated CFA2 --- there was no
recipe for how to do this for one's favorite control operator. This
paper seeks to do just that with an operational view of what
summarization is, in essence. In other words, we give a concrete
semantics to the tricks that the analyses in the literature use in the
abstract. We also give intuitive analogies to well-established
ideas/techniques so that you too can write a pushdown analysis for
your language. In order to demonstrate the applicability of this
viewpoint, we show a new analysis for a language with composable
control. All of the semantics modeled in this paper are implemented in
full detail in PLT Redex and available at

\begin{center}
  \url{http://github.com/ianj/concrete-summaries}
\end{center}

The remaining sections of the paper are
\begin{itemize}
\item{section \ref{sec:pdcfa}: we derive a cousin of PDCFA}
\item{section \ref{sec:cfa2}: we make additions to the previous semantics to get a direct-style CFA2 without first-class control}
\item{section \ref{sec:sr}: we give a novel analysis of delimited and composable first-class control.}
\end{itemize}

\section{Deriving PDCFA}
\label{sec:pdcfa}

PDCFA does not have some orthogonal semantic components that CFA2
features to improve precision, so we start by deriving PDCFA from an
operational semantics for the untyped lambda calculus (figure
\ref{fig:base-semantics}). The semantic spaces for the machine follow.

\begin{align*}
  \mexpr \in \Expr &= \svar{\mvar} \mid \sapp{\mexpr}{\mexpr} \mid \slam{\mvar}{\mexpr} \\
  \mstate \in \State &= (\Expr \times \Env) \times \Store \times \Kont \\
  \mval \in \Value &::= \vclo{\slam{\mvar}{\mexpr}}{\menv} \\
  \mkont \in \Kont &::= \kmt \mid \kar{\mexpr,\menv,\mkont} \mid \kfn{\mval,\mkont} \\
  \menv \in \Env &= \Var \to \Addr \\
  \mstore \in \Store &= \Addr \to \wp(\Value) \\
  \mvar \in \Var &\text{ an infinite set} \\
  \maddr \in \Addr &\text{ an infinite set}
\end{align*}

The $\Addr$ space is what controls the precision of the model. For a
concrete semantics, we require the allocation metafunction $\alloc :
\State \to \Addr$ to return fresh addresses ($\maddr \notin
\dom(\mstore)$), but any choice of address is sound.

\begin{figure}
  \centering
  $\mstate \stepto \mstate' \text{ where } \maddr = \alloc(\mstate)$ \\
  \begin{tabular}{r|l}
    \hline
% variable lookup
    $\tpl{(\svar\mvar, \menv), \mstore, \mkont}$
    &
    $\tpl{\mval,\mstore,\mkont}$ if $\mval \in \mstore(\menv(\mvar))$
    \\
% application
    $\tpl{(\sapp{\mexpri0}{\mexpri1}, \menv), \mstore, \mkont}$
    &
    $\tpl{(\mexpri0, \menv), \mstore, \kar{\mexpri,\menv,\mkont}}$
    \\
% argument evaluation
    $\tpl{\mval, \mstore, \kar{\mexpr,\menv,\mkont}}$
    &
    $\tpl{(\mexpr, \menv), \mstore, \kfn{\mval, \mkont}}$
    \\
% function call
    $\tpl{\mval,\mstore,\kfn{\vclo{\slam{\mvar}{\mexpr}}{\menv}, \mkont}}$
    &
    $\tpl{(\mexpr, \extm{\menv}{\mvar}{\maddr}), \joinone{\mstore}{\maddr}{\mval}, \mkont}$
  \end{tabular}
  \caption{The CESK machine}
  \label{fig:base-semantics}
\end{figure}

Since PDCFA is a simpler analysis than CFA2, it enjoys a polynomial
complexity in the monovariant case. Its final ${\mathcal O}(n^6)$ form
is a naive ``step all states'' widening, which yields poor
results. The common widening uses a worklist to only step states that
need stepping --- the fact that the store is shared amongst all states
makes this a semantic difference, and not just an implementation
difference. Doing this bumps the complexity up to ${\mathcal
  O}(n^9)$\footnote{The available \emph{implementations} of PDCFA
  indeed do this and are themselves ${\mathcal O}(n^9)$.}. These
bounds are (rough) absolute worst case that is highly unlikely, if
ever, happen in practice. The worklist abstraction restricts value
flow to fewer spurious paths, often leading to a faster analysis than
a typical 0CFA.

\paragraph{Tracking return points:} the magic of the method is in
keeping a table of (local) continuations for each function and store
pair. This closely mirrors the technique of store-allocating
continuations used in AAM. Instead of deferring to the table (store)
for the remainder of a continuation for each frame, we only have
indirections at function call boundaries. Note that since AAM is about
finitizing the state space, this step itself fits within the AAM
method, since continuations within functions truncated at call
boundaries are bounded by the nesting depth of those functions,
thereby making the continuation space finite. In the monovariant case,
the number of continuations is still linear in the size of the
program.

The tail of a continuation in the context of a function will contain
the stackless context in which the function was called, in order to
link up with the proper call-site(s). The context includes the
function (or unique label of the function), the environment, and the
store. Notice that this choice can be viewed as a special allocation
strategy for continuations in the AAM viewpoint; the store is the
important ingredient to maintaining enough precision to keep a
pushdown abstraction. We separate the concepts in this paper for the
exposition. The semantic spaces for the machine are modified thusly:

\begin{align*}
  \mstate \in \State &= (\Expr \times \Env) \times \Store \times \Kont \times \KTab \times \Memo \\
  \mkont \in \Kont &::= \kmt
                     \mid \kar{\mexpr,\menv,\mkont} 
                     \mid \kfn{\mval,\mkont}
                     \mid \krt{(\mexpr,\menv),\mstore}\\
  \mktab \in \KTab &= (\Expr \times \Env)\times \Store \to \wp(\Kont) \\
  \mmemo \in \Memo &= (\Expr \times \Env)\times \Store \to \wp(\Value)
\end{align*}

\paragraph{The role of summaries:} notice the additional $\Memo$
component. A ``summary edge'' in CFA2 or equivalently an
$\epsilon$-edge in PDCFA is an edge from the source of a push edge to
the target of the matching pop edge. ``Matching'' here means there is
a path through machine reductions that don't change the stack, or
through summary edges. In our model, we only ``push'' when we call a
function, and we only ``pop'' when we return with a value. There is an
analogy to something more operational: summary edges embody
memoization. Instead of following an entire path through a call to
return a value, we simply jump from the call to the return (the result
of the call). We will return to this analogy and what it
means in the presence of first-class control in section \ref{sec:sr}.

\begin{figure}
  \centering
  $\mstate \stepto \mstate' \text{ where } \maddr = \alloc(\mstate)$ \\
  \begin{tabular}{r|l}
    \hline
% variable lookup
    $\tpl{(\svar\mvar, \menv), \mstore, \mkont, \mktab, \mmemo}$
    &
    $\tpl{\mval,\mstore,\mkont, \mktab, \mmemo}$ if $\mval \in \mstore(\menv(\mvar))$
    \\
% application
    $\tpl{(\sapp{\mexpri0}{\mexpri1}, \menv), \mstore, \mkont, \mktab, \mmemo}$
    &
    $\tpl{(\mexpri0, \menv), \mstore, \kar{\mexpri1,\menv,\mkont}, \mktab, \mmemo}$
    \\
% argument evaluation
    $\tpl{\mval, \mstore, \kar{\mexpr,\menv,\mkont}, \mktab, \mmemo}$
    &
    $\tpl{(\mexpr, \menv), \mstore, \kfn{\mval, \mkont}, \mktab, \mmemo}$
    \\
% function call
    $\tpl{\mval,\mstore,\kfn{\vclo{\slam{\mvar}{\mexpr}}{\menv}, \mkont},\mktab,\mmemo}$
    & % actually do call,
    $\tpl{\mpoint,
          \mstore',
          \krt{\mpoint, \mstore'},
          \joinone{\mktab}{(\mpoint, \mstore')}{\mkont},
          \mmemo}$
\\
    & $\tpl{\mval, \mstore', \mkont, \mktab, \mmemo} \text{ if } \mval \in \mmemo(\mpoint,\mstore')$
    \\ % or, lookup in table
%    & $\tpl{\mval, \mstore', \mkont,\mktab,\mmemo}$ if $\mval \in \mmemo(\mpoint, \mstore')$ \\    
    where & $\mpoint = (\mexpr, \extm{\menv}{\mvar}{\maddr})$ \\
          & $\mstore' = \joinone{\mstore}{\maddr}{\mval}$
    \\
% return
    $\tpl{\mval, \mstore, \krt{\mpoint,\mstore'}, \mktab, \mmemo}$
    &
    $\tpl{\mval, \mstore, \mkont, \mktab, \joinone{\mmemo}{(\mpoint, \mstore')}{\mval}}$
    if $\mkont \in \mktab(\mpoint, \mstore')$
  \end{tabular}
  \caption{The summarizing tabular stack machine}
  \label{fig:summary-semantics}
\end{figure}

Once we finitize the address space of the store, this computes a
characteristic finite state machine that has only reachable states of
the pushdown system the unbounded stack model embodies.
To turn this semantics into PDCFA's (implemented) algorithm for constructing a Dyck
state graph, we apply a widening operator ${\mathcal F}$ to make $\mstore$, $\mkont$,
and $\mmemo$ shared amongst all states.

\begin{align*}
  \mastate \in \sa{State} &= (\Expr \times \Env) \times \Kont \\
  \System &= \wp(\sa{State} \times \Store) \times \wp(\sa{State}) \times \Store \times \KTab \times \Memo \\
  {\mathcal F} &: \System \to \System \\
  {\mathcal F}(S, F, \mstore, \mktab, \mmemo) &= (S \cup S', F', \mstore', \mktab', \mmemo') \\
  \text{where } I &= \setbuild{\mstate'}{\mastate \in F, \wn(\mastate,\mstore,\mktab,\mmemo) \stepto \mstate'} \\
                \mstore' &= \bigsqcup\setbuild{\mstore'}{\wn(\_, \mstore',\_,\_) \in I} \\
                \mktab' &=  \bigsqcup\setbuild{\mktab'}{\wn(\_, \_, \mktab', \_) \in I} \\
                \mmemo' &=  \bigsqcup\setbuild{\mmemo'}{\wn(\_, \_, \_, \mmemo') \in I} \\
                S' &= \setbuild{(\mastate',\mstore')}{\wn(\mastate', \_, \_, \_) \in I} \\
                F' &= \setbuild{\mastate'}{(\mastate',\_) \in S' \setminus S} \\
                \wn(\tpl{(\mexpr,\menv),\mkont},\mstore,\mktab,\mmemo)
                   &= \tpl{(\mexpr,\menv),\mstore,\mkont,\mktab,\mmemo}
\end{align*}

A $\System$ embodies the states seen and at which store, $S$, the
frontier set of states yet to analyze, $F$, the shared store for the
frontier, $\mstore$, the continuation table $\mktab$ and the memo
table $\mmemo$. All the states in the frontier are stepped with the
current store, after which the next store is the least upper bound of
all the resulting stores. The next frontier contains only states
resulting from stepping the previous frontier that we haven't seen at
this next store. Systematic techniques for a performant implementation
can be found in \citet{ianjohnson:oaam:2013}.

\section{Deriving CFA2}
\label{sec:cfa2}

CFA2 is the first published analysis of a higher-order programming
language that could properly match calls and returns. We will show
that it fits well into the same presentation we gave for
PDCFA. Vardoulakis and Shivers had a clear goal of harnessing the
extra information a pushdown model provides to produce a
high-precision analysis that works well in practice. This resulted in
more than just the call/return matching of the previous section, which
is why we are showing the two separately. There are two orthogonal
features of the semantics:
\begin{enumerate}
\item{stack allocation for some bindings}
\item{strong updates on stack frames for resolved nondeterminism}
\end{enumerate}
The first of these is an addition to the stackless context. There is a
conservative pre-analysis that checks locally whether a binding will
never escape, and classifies references as able to use the stack frame
or not. Their criteria for a binding never escaping is that it is
never referenced in a function that is not its binder. This can be
extended in a language with more linguistic features; see Kranz's
thesis about register-allocatable bindings in the Orbit Scheme
compiler \citep{ianjohnson:kranz:thesis:1988}. A stackable reference
is one that appears in the body of the binding function, by which we
mean not within the body of nested function. They use the information
that a binding never escapes to not bother allocating it in the
heap. This has the advantage of not changing the heap, and thus leads
to less propagation. The addition of these stack frames makes the
analysis exponential in theory, though in practice they have been
observed to decrease running time in most cases.

The second of these is to ameliorate a problem they call ``fake
rebinding.'' That is, since bindings in the abstract represent several
values, we don't want to reference a variable \texttt{x} in two
different places and have it resolve to two different values. In AAM,
a variable reference non-deterministically steps to all possible
values associated with that variable. Here we want to say that once
\texttt{x} is considered to stand for value $v$, then all subsequent
references of \texttt{x} should be $v$. If they aren't, it looks as if
\texttt{x} was rebound; it hasn't, and thus it is a ``fake
rebinding.'' CFA2 does not step to all values on variable reference,
but instead carries all its values around in superposition until they
need to be observed at, say, a function call. We give a simplified
semantics that is more along the AAM style, but CFA2's approach can
easily be recovered from it\footnote{Our Redex model implements the fake rebinding fix after function return}.

We show only the significantly modified rules of the semantics in
figure \ref{fig:frame-semantics}. The other rules simply carry along
the extra $\mframe$ component untouched.
\begin{figure}
  \centering
  $\mstate \stepto \mstate' \text{ where } \maddr = \alloc(\mstate)$ \\
  \begin{tabular}{r|l}
    \hline
% variable lookup
    $\tpl{(\svar[\mlab]{\mvar}, \menv), \mstore, \mframe, \mkont}$
    &
    $\tpl{\mval,\mstore,\mframe',\mkont}$ if $(\mframe', \mval) \in \lookup(\mstore,\mframe,\menv,\mvar,\mlab)$
    \\
% % application
%     $\tpl{(\sapp{\mexpri0}{\mexpri1}, \menv), \mstore, \mframe, \mkont}$
%     &
%     $\tpl{(\mexpri0, \menv), \mstore, \mframe, \kar{\mexpri1,\menv,\mkont}}$
%     \\
% % argument evaluation
%     $\tpl{\mval, \mstore, \mframe, \kar{\mexpr,\menv,\mkont}}$
%     &
%     $\tpl{(\mexpr, \menv), \mstore, \mframe, \kfn{\mval, \mkont}}$
%     \\
% function call
    $\tpl{\mval,\mstore,\mframe,\kfn{\vclo{\slam{\mvar}{\mexpr}}{\menv}, \mkont}}$
    &
    $\tpl{(\mexpr, \extm{\menv}{\mvar}{\maddr}), \mstore', \mframe', \mkont}$
    \\ where & $(\mstore',\mframe') = \bind(\mstore,\mframe,\maddr,\mvar,\mval)$
  \end{tabular}
  \caption{The CES$\xi$K machine}
  \label{fig:frame-semantics}
\end{figure}

The metafunctions the semantics uses to entend and consult the heap
and stack use implicit information from the preanalysis we described
above:

\begin{align*}
  \bind(\mstore,\mframe,\maddr,\mvar,\mval) &=
   \left\{\begin{array}{ll}
            (\mstore, \snglm{\maddr}{\mval}) & \text{if } \mvar \text{ never escapes} \\
            (\joinone{\mstore}{\maddr}{\mval}, \snglm{\maddr}{\mval}) & \text{otherwise } \\
          \end{array}\right. \\
  \lookup(\mstore,\mframe,\menv,\mvar,\mlab) &=
    \left\{\begin{array}{ll}
          \setbuild{(\extm{\mframe}{\menv(\mvar)}{\set{\mval}}, \mval)}
                   {\mval \in \mframe(\menv(\mvar))}
                   & \text{if } \mlab \text{ non-escaping} \\
          \setbuild{(\mframe,\mval)}{\mval \in \mstore(\menv(\mvar))} & \text{otherwise}
           \end{array}\right.
\end{align*}

Sidestepping fake rebinding does not need to be restricted to
stackable references, but that is what CFA2 does. Indeed, as soon as
the nondeterminism has been determined, we could extend the stack
frame so any subsequent reference means what it meant previously in
the function. Lookup would then always try the stack frame before
falling back on the heap.

The widening we applied to PDCFA also applies here in order to get
CFA2. Both PDCFA and CFA2 use $\epsilon$-edges and summaries to
seemingly skip work when new stacks reach a function, but the summary
is not likely to be there, so we just drop that whole bit of
complexity from the semantics. CFA2 also included what they called
``transitive summaries'' to deal with tail calls. We insert an $\rt$
frame at every function call.  This view contends with tail calls, but
we can identify tail calls easily --- any call with an $\rt$ as its
continuation is a tail call. Tail calls are important in language
implementations for space complexity reasons
\citep{ianjohnson:clinger:tail-calls:1998}, but in an analysis, these
concerns are less important. The repeated popping of $\rt$ inserted
by what otherwise were tail-calls is synonymous with CFA2's transitive
summaries.

\section{Analysis of delimited, composable control}
\label{sec:sr}

There is contention among programming language researchers whether
\rackett{call/cc} should be a language primitive, since it captures
the entire stack, leading to space leaks
\citep{ianjohnson:kiselyov:against-callcc}. Alternative control
operators have been proposed that delimit how much of the stack to
capture, such as Felleisen's $\%$ (read ``prompt'') and capture
operator ${\mathcal F}$ (read ``control'')
\citep{ianjohnson:felleisen:control:1988}, or Danvy and Filinski's
\texttt{reset} (equivalent to $\%$) and \texttt{shift}
\citep{ianjohnson:danvy:filinski:delim:1990}. However, the stacks
captured by these operators always extend the stack when invoked,
rather than replace it like those captured with
\rackett{call/cc}. Continuations that have this extension behavior are
called ``composable continuations.'' Stack replacement is simple to
model in a regular analysis using the AAM approach, and Vardoulakis
and Shivers showed it can be done in a pushdown approach (although it
breaks the pushdown model). Stack extension, however, poses a new
challenge for pushdown analysis, since one application of a composable
continuation means pushing an unbounded amount of frames onto the
stack. Vardoulakis' and Shivers' approach does not immediately apply
in this situation, since their technique drops all knowledge of the
stack at a continuation's invocation site; extension, however, must
preserve it.

The way we have been splitting continuations at function calls has
similarities to the meta-continuation approach to modeling delimited
control, given in figure \ref{fig:shift-reset} (adapted from
~\citep{ianjohnson:Biernacki2006274}). We could view each function
call as inserting a prompt, and returns as aborting to the nearest
prompt. The changed semantic spaces for the shift/reset semantics are as
follows:

\begin{align*}
  \mstate \in \State &::= \tpl{\mpoint, \mstore, \mkont, \mmkont} \\
  \mpoint \in \Point &::= (\mexpr, \menv) \mid \mval \\
  \mval \in \Value &::= \vclo{\slam{\mvar}{\mexpr}}{\menv} \mid \vcomp{\mkont} \\
  \mmkont \in \MKont &::= \kmt \mid \mkapp{\mkont}{\mmkont}
\end{align*}

\begin{figure}
  \centering
  $\mstate \stepto \mstate' \text{ where } \maddr = \alloc(\mstate)$ \\
  \begin{tabular}{r|l}
    \hline
% Reset
    $\tpl{(\sreset{\mexpr}, \menv), \mstore, \mkont, \mmkont}$
    &
    $\tpl{(\mexpr, \menv), \mstore, \kmt, \mkapp{\mkont}{\mmkont}}$
    \\
% Pop prompt
    $\tpl{\mval, \mstore, \kmt, \mkapp{\mkont}{\mmkont}}$
    &
    $\tpl{\mval, \mstore, {\mkont}, {\mmkont}}$
    \\
% Shift
    $\tpl{(\sshift{\mvar}{\mexpr}, \menv), \mstore, \mkont, \mmkont}$
    &
    $\tpl{(\mexpr, \extm{\menv}{\mvar}{\maddr}), \joinone{\mstore}{\maddr}{\mkont},\kmt,\mmkont}$
    \\
% continuation call
    $\tpl{\mval,\mstore,\kfn{\mkont', \mkont}, \mmkont}$
    &
    $\tpl{\mval, \mstore, \mkont', \mkapp{\mkont}{\mmkont}}$
  \end{tabular}  
  \caption{Machine semantics for shift/reset}
  \label{fig:shift-reset}
\end{figure}

Turning this into a table-based semantics involves making prompts a
point of indirection, just like function calls. Memoization also gets
a new context to consider, calling a continuation, because composable
continuations act like functions. The new semantic spaces are then

\begin{align*}
  \mctx \in \Context &::= ((\mexpr,\menv),\mstore) \mid (\vcomp{\mkont},\mval,\mstore) \\
  \mkont \in \Kont &= \kmt \mid \krt{\mctx} \mid \kar{\mexpr,\menv,\mkont} \mid \kfn{\mval,\mkont} \\
  \mmkont \in \MKont &::= \kmt \mid \kprompt{\mctx} \\
  \mktab \in \KTab &= \Context \to (\wp(\Kont \times \MKont) \cup \Kont) \\
  \mmemo \in \Memo &= \Context \to \wp(\Value)
\end{align*}

Figure \ref{fig:shift-reset-table0} has what one might naturally write
using just this information. Unfortunately, since $\rt$ frames contain
a store, and continuations can now appear in the store, this
introduces a circularity that could cause the analysis to never
terminate. For example, a loop that continually captures continuations
would introduce unboundedly many continuation values due to the
ever-growing store. This means the store is not finite height, and
there may be no fixed point.

\paragraph{Possible fixes to non-termination:} The simplest fix to the
circularity would be to strip stores out of the context of the $\rt$
frame in a captured continuation, and additionally consider contexts
with a stripped store an abstraction of the same context with any
store. This is a fairly brutal approximation of a captured
continuation, so an alternative is to make this tunable with our
precision-tuning friend, $\alloc$. Then, instead of entirely removing
the store component of the $\rt$ context, we can replace it with an
address of possible stores that it would approximate.

\begin{figure}
  \centering
  $\mstate \stepto \mstate' \text{ where } \maddr = \alloc(\mstate)$ \\
  \begin{tabular}{r|l}
    \hline
% Reset
    $\tpl{(\sreset{\mexpr}, \menv), \mstore, \mkont, \mmkont, \mktab, \mmemo}$
    &
    $\tpl{\mpoint, \mstore, \kmt, \kprompt{\mctx}, \joinone{\mktab}{\mctx}{(\mkont,\mmkont)}, \mmemo}$
    \\
    where & $\mpoint = (\mexpr, \menv)$, $\mctx = (\mpoint, \mstore)$.
    \\
% Pop prompt
    $\tpl{\mval, \mstore, \kmt, \kprompt{\mctx}, \mktab, \mmemo}$
    &
    $\tpl{\mval, \mstore, {\mkont}, {\mmkont}, \mktab, \joinone{\mmemo}{\mctx}{\mval}}$
    if $(\mkont,\mmkont) \in \mktab(\mctx)$
    \\
% Shift
    $\tpl{(\sshift{\mvar}{\mexpr}, \menv), \mstore, \mkont, \mmkont, \mktab, \mmemo}$
    &
    $\tpl{(\mexpr, \extm{\menv}{\mvar}{\maddr}), \joinone{\mstore}{\maddr}{\vcomp{\mkont}},\kmt,\mmkont,\mktab,\mmemo}$
    \\
% continuation call
    $\tpl{\mval,\mstore,\kfn{\vcomp{\mkont'}, \mkont}, \mmkont, \mktab, \mmemo}$
    &
    $\tpl{\mval, \mstore, \mkont', \kprompt{\mctx}, \mktab',\mmemo}$
    \\
    where & $\mctx = (\mkont, \mval, \mstore')$ \\
          & $\mktab' = \joinone{\mktab}{\mctx}{(\mkont,\mmkont)}$
    \\
% Memoized continuation call
% continuation call
    $\tpl{\mval,\mstore,\kfn{\vcomp{\mkont'}, \mkont}, \mmkont, \mktab, \mmemo}$
    &
    $\tpl{\mval', \mstore, \mkont, \mmkont, \mktab,\mmemo}$ if $\mval' \in \mmemo(\mkont',\mval,\mstore)$
  \end{tabular}  
  \caption{Faulty table-based semantics for shift/reset}
  \label{fig:shift-reset-table0}
\end{figure}

The new indirection possibility changes $\Context$ to also include
$\maddr$ where there was previously a $\mstore$ (though contexts for
continuation calls remain unchanged), and $\KTab$ now additionally
maps $\Addr$ to a set of stores. The rules that change are presented in figure \ref{fig:shift-reset-table1}.

\begin{align*}
  \mctx \in \Context &::= ((\mexpr,\menv),\mstore) \mid ((\mexpr,\menv),\maddr) \mid (\vcomp{\mkont},\mval,\mstore) \\
  \msctx \in \SContext &::= ((\mexpr,\menv),\maddr) \\
  \mskont \in \SKont &= \krt{\msctx} \mid \ldots \\
  \mval \in \Value &= \vclo{\slam{\mvar}{\mexpr}}{\menv} \mid \vcomp{\mskont} \\
  \mmkont \in \MKont &::= \kmt \mid \kprompt{\mctx} \\
  \mktab \in \KTab &= (\Context \to (\wp(\Kont \times \MKont) \cup \Kont)) \\
                   &\cup (\Addr \to \wp(\Store))
\end{align*}

\begin{figure}
  \centering
% Shift
  $\mstate \stepto \mstate' \text{ where } \maddr = \alloc(\mstate)$ \\
  \begin{tabular}{r|l}
    \hline
    $\tpl{(\sshift{\mvar}{\mexpr}, \menv), \mstore, \mkont, \mmkont, \mktab, \mmemo}$
    &
    $\tpl{(\mexpr, \extm{\menv}{\mvar}{\maddr}), \joinone{\mstore}{\maddr}{\vcomp{\mkont'}},\kmt,\mmkont,\mktab',\mmemo}$
    \\
    where & $\maddr = \alloc(\varsigma)$, $(\mkont',\mktab') = \approximate(\mkont, \mktab, \maddr)$
\\
% Return
   $\tpl{\mval, \mstore, \krt{\mctx}, \mmkont, \mktab, \mmemo}$
   &
   $\tpl{\mval, \mstore, \mkont, \mmkont, \mktab, \mmemo'}$
   if $\mkont \in \returns(\mktab, \mctx)$
   \\
   where & $\mmemo' = \memoize(\mmemo, \mktab, \mctx, \mval)$
  \end{tabular}
  \caption{Fixed table-based semantics for shift/reset}
  \label{fig:shift-reset-table1}
\end{figure}

The metafunctions mentioned in the fixed semantics all deal with the
addition of $\maddr$ to contexts. If the context in an $\rt$ frame is
approximate, we must return to all the continuations known for all the
contexts it approximates ($\returns$). At return boundaries, the memo
table must add the result to all the represented contexts
($\memoize$). At capture time, we strip the store in the $\rt$ frame
if there is one, and replace it with an address.

\newcommand{\replacectx}{\mathit{replace}\mstore}
\newcommand{\addstore}{\mathit{add}\mstore}
\begin{align*}
  \returns(\mktab, ((\mexpr,\menv), \mstore)) &= \mktab((\mexpr,\menv), \mstore) \\
  \returns(\mktab, ((\mexpr,\menv), \maddr)) &=
    \bigcup\setbuild{\mktab((\mexpr,\menv),\mstore)}{\mstore \in \mktab(\maddr)}
  \\[2pt]
  \memoize(\mmemo, \mktab, ((\mexpr,\menv), \mstore), \mval) &=
    \joinone{\mmemo}{((\mexpr,\menv), \mstore)}{\mval} \\
  \memoize(\mmemo, \mktab, ((\mexpr,\menv), \maddr), \mval) &=
    \mmemo \sqcup \bigsqcup\limits_{\mstore \in \mktab(\maddr)}\snglm{((\mexpr,\menv), \mstore)}{\mval}
  \\[2pt]
  \approximate(\mkont, \mktab, \maddr) &= (\replacectx(\mkont), \addstore{\mkont}) \\
  \text{where }
   \replacectx(\kmt) &= \kmt \\
   \replacectx(\krt{((\mexpr,\menv),\_)}) &= \krt{((\mexpr,\menv),\maddr)} \\
   \replacectx(\kar{\mexpr,\menv,\mkont}) &= \kar{\mexpr,\menv,\replacectx(\mkont)} \\
   \replacectx(\kfn{\mval, \mkont}) &= \kfn{\mval,\replacectx(\mkont)}
  \\[2pt]
   \addstore(\kmt) &= \mktab \\
   \addstore(\krt{((\mexpr,\menv),\mstore)}) &= \joinone{\mktab}{\maddr}{\mstore} \\
   \addstore(\krt{((\mexpr,\menv),\maddr')}) &= \joinm{\mktab}{\maddr}{\mktab(\maddr')} \\
   \addstore(\kar{\mexpr,\menv,\mkont}) &= \addstore(\mkont) \\
   \addstore(\kfn{\mval, \mkont}) &= \addstore(\mkont)
\end{align*}

The result of this viewpoint is a sound, precise, and computable
semantics for a ``pushdown approach'' to analyzing delimited,
composable control. To handle non-composable control, we can simply
remove the prompts and keep $\approximate$.

\section{Related Work}

The immediately related work is that of PDCFA
\citet{ianjohnson:earl2010pdcfa},
CFA2~\citet{ianjohnson:vardoulakis-lmcs11,
  ianjohnson:Vardoulakis2011Pushdown}, and AAM
~\citet{dvanhorn:VanHorn2010Abstracting}, the first two of which we
recreated in full detail. The version of CFA2 that handles
\rackett{call/cc} does not handle composable control, and is dependent
on a restricted CPS representation. They also had no way to tune the
precision of their first class continuation approximation. Since
\rackett{call/cc} can be simulated with shift/reset, this work
supercedes theirs.

Pushdown models have existed in the first-order static analysis
literature ~\citet[Chapter
7]{local:muchnick:jones:flow-analysis:1981}\citet{ianjohnson:reps:pushdown:1995},
and the first-order model checking literature
\citet{ianjohnson:bouajiani:esparza:pushdown:1997}, for some time. The
higher-order setting imposes additional challenges that make their
methods difficult to adapt. The most important constraint is that we
can't know all call-sites of a function/method before the analysis
begins, which their methods heavily rely on.

\section{Conclusion}

As the programming world continues to embrace behavioral values, it
becomes more important to import the powerful techniques pioneered by
the first-order analysis and model checking communities. CFA2 and
PDCFA paved the way, and in large part inspired this work. It is our
view that systematic approaches to applying the techniques are pivotal
to scaling them to ``real languages.'' We believe that the recipe that
this paper set forth is a step in that direction. That is, make
continuation tables keyed with enough context, and memoize at the
introduced indirection points. The result in a language with
well-bracketed control is a ``pushdown analysis'' using
summarization. In a language without well-bracketed control, we are
not chained to a pushdown automaton as the target of the
approximation, so the techniques still apply and give better precision
than regular methods.

\bibliographystyle{chicago}
\bibliography{bibliography}

\end{document}